{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📚 구체적인 과제 수행 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1️⃣ 데이터셋 탐색\n",
    "\n",
    "- pandas 라이브러리의 read 함수 사용하여 데이터 파일을 데이터프레임으로 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030   NaN  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90    NaN  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99    NaN  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기 (보스턴 주택 가격 데이터셋)\n",
    "import pandas as pd\n",
    "\n",
    "# csv 파일 불러오기 (./는 현재 디렉토리에 있는 파일을 가져오겠다는 뜻이다.)\n",
    "df = pd.read_csv('./supervised_learning_data/housingdata.csv')\n",
    "\n",
    "# 전체 데이터프레임 확인\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "housingdata.csv 데이터 탐색\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     486 non-null    float64\n",
      " 1   ZN       486 non-null    float64\n",
      " 2   INDUS    486 non-null    float64\n",
      " 3   CHAS     486 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      486 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    int64  \n",
      " 9   TAX      506 non-null    int64  \n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    486 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 55.5 KB\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "컬럼 : ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "데이터프레임의 크기 (행,열) : (506, 14)\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.611874</td>\n",
       "      <td>11.211934</td>\n",
       "      <td>11.083992</td>\n",
       "      <td>0.069959</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.518519</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.715432</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.720192</td>\n",
       "      <td>23.388876</td>\n",
       "      <td>6.835896</td>\n",
       "      <td>0.255340</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>27.999513</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.155871</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.081900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.175000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.253715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>76.800000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.430000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.560263</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>93.975000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  486.000000  486.000000  486.000000  486.000000  506.000000  506.000000   \n",
       "mean     3.611874   11.211934   11.083992    0.069959    0.554695    6.284634   \n",
       "std      8.720192   23.388876    6.835896    0.255340    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.081900    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.253715    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.560263   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  486.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.518519    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     27.999513    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.175000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     76.800000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     93.975000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT        MEDV  \n",
       "count  486.000000  506.000000  \n",
       "mean    12.715432   22.532806  \n",
       "std      7.155871    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      7.125000   17.025000  \n",
       "50%     11.430000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('housingdata.csv 데이터 탐색')\n",
    "print('-'*130)\n",
    "\n",
    "# 데이터프레임의 정보 확인 (컬럼, 결측값, 데이터 타입 등)\n",
    "df.info()\n",
    "print('-'*130)\n",
    "\n",
    "print(f'컬럼 : {list(df.columns)}')\n",
    "print('-'*130)\n",
    "\n",
    "print(f'데이터프레임의 크기 (행,열) : {df.shape}')\n",
    "print('-'*130)\n",
    "\n",
    "# 데이터프레임의 요약 통계량 확인\n",
    "df.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 💡 housingdata.csv 파일을 데이터프레임으로 만든 후 여러 메서드를 사용해 탐색한 결과\n",
    "\n",
    "1. 506행, 14열의 데이터프레임이다.\n",
    "2. 총 14개의 컬럼이 존재한다. ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV' ]\n",
    "3. range index(연속 정수형 인덱스)가 총 506개, 즉, 0부터 505인덱스까지 있음을 알 수 있다.\n",
    "4. 따라서, Non-Null Count가 506 non-null이 아닌 ['CRIM', 'ZN', 'INDUS', 'CHAS','AGE','LSTAT'] 컬럼은 결측값이 있는 것임을 알 수 있다. \n",
    "5. 'RAD', 'TAX'는 정수형, 그 외는 모두 실수형 데이터 타입이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2️⃣ 데이터셋 전처리 (결측치 처리, 이상치 탐지 및 제거, 특징 선택)\n",
    "##### 💡 전처리는 데이터 분석 및 머신러닝 모델링을 위해 데이터를 준비하는 과정으로, 데이터의 품질을 높이고 분석 결과의 신뢰성을 확보하기 위한 필수적인 과정 \n",
    "##### 📝 결측치 처리 (데이터셋에서 누락된 값을 처리하는 작업) : 결측치를 처리하지 않으면 모델의 성능이 저하될 수 있다.\n",
    "\n",
    "- 결측값이나 이상치는 데이터의 품질을 저하시킬 수 있다. 데이터 품질이 낮으면 모델의 성능이 떨어질 수 있고, 잘못된 예측을 할 가능성이 높아진다.\n",
    "- 결측값이 포함된 데이터는 계산 과정에서 오류를 발생시킬 수 있으며, 이상치는 모델의 파라미터에 큰 영향을 미쳐 잘못된 학습 결과를 초래할 수 있다.\n",
    "- 결측값과 이상치를 적절히 처리하면 모델의 일반화 능력과 예측 성능이 향상될 수 있다. 이는 모델이 새로운 데이터에 대해 더 나은 예측을 할 수 있게 해준다.\n",
    "\n",
    "  - 제거 : 결측치가 있는 행이나 열을 제거한다. 정확한 데이터만 가질 수 있어 결측치가 적을 때는 유용하지만, **데이터 손실**이 발생할 수 있다.\n",
    "  - 대체 : 평균, 중앙값, 최빈값 등으로 결측치를 대체한다.\n",
    "  - 예측 : 다른 특성을 사용하여 결측치를 예측하고 채운다.\n",
    "\n",
    "\n",
    "➡️ 해당 데이터의 특성에 맞게 결측치를 처리해야 한다.**다양한 방법을 시도**해보고 가장 적합한 방법을 선택하는 것이 중요하다.\n",
    "\n",
    "##### 📝 현재 결측치가 있는 컬럼들\n",
    "\n",
    "- **CRIM**: 마을별 1인당 범죄율 [mean : 3.611874 / min : 0.006320 / max : 88.976200]\n",
    "    - 최댓값이 크긴하지만 평균값을 봤을 때 대체로 작은 값에 몰려있는 것 같아, 평균값으로 대체해주겠다.\n",
    "- **ZN**: 25,000평방피트 이상의 부지에 대해 구획된 주거용 토지의 비율 [mean : 11.211934 / min : 0.000000 / max : 100.000000]\n",
    "    - 데이터를 봤을 때 0이 이어지다가 어디는 수치가 몰려있는, 군집화된 양상을 띄고 있다. 비어있는 결측값에 아무거나 넣어놓으면 군집화가 깨질 수도 있을 것 같아, 결측값이 있는 행은 제거하겠다.\n",
    "- **INDUS**: 마을별 비소매업무 지역 비율 [mean : 11.083992 / min : 0.460000 / max : 27.740000]\n",
    "    - 값이 최솟값부터 최댓값까지 고루 분포하는 양상을 보여서, 평균값으로 대체해주겠다.\n",
    "- **CHAS**: 찰스 강 더미 변수 (강이 인접한 경우 1, 그렇지 않으면 0) [mean : 0.069959 / min : 0.000000 / max : 1.000000]\n",
    "    - 더미형 데이터의 경우 결측값은 날려버리는 것도 괜찮다고 해서 결측값이 있는 행을 제거하겠다. \n",
    "- **AGE**: 1940년 이전에 지어진 소유주 점유 비율 [mean : 68.518519 / min : 2.900000 / max : 100.000000]\n",
    "    - 값이 고루 분포하는 양상을 보여서, 평균값으로 대체해주겠다. \n",
    "- **LSTAT**: 인구 중 저소득층 비율 [mean : 12.715432 / min : 1.730000 / max : 37.970000]\n",
    "    - 값이 고루 분포하는 양상을 보여서, 평균값으로 대체해주겠다.\n",
    "\n",
    "➡️ 선형회귀 모델 등을 사용하여 결측값을 예측한 후 넣어줄 수도 있으나 일단 대체하는 방법으로 과제를 진행해보겠다.\n",
    "\n",
    "✏️ 결측값을 모조리 제거하고 학습한 모델, 결측값을 모조리 평균값으로 대체한 모델, 선형회귀모델을 통해 결측값을 예측해서 채워준 모델보다, 위에 적어놓은 것대로 결측값을 적당히 처리하고 학습한 모델의 성능이 더 좋았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 컬럼들의 결측값 현황\n",
      "CRIM       0\n",
      "ZN         0\n",
      "INDUS      0\n",
      "CHAS       0\n",
      "NOX        0\n",
      "RM         0\n",
      "AGE        0\n",
      "DIS        0\n",
      "RAD        0\n",
      "TAX        0\n",
      "PTRATIO    0\n",
      "B          0\n",
      "LSTAT      0\n",
      "MEDV       0\n",
      "dtype: int64\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 466 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     466 non-null    float64\n",
      " 1   ZN       466 non-null    float64\n",
      " 2   INDUS    466 non-null    float64\n",
      " 3   CHAS     466 non-null    float64\n",
      " 4   NOX      466 non-null    float64\n",
      " 5   RM       466 non-null    float64\n",
      " 6   AGE      466 non-null    float64\n",
      " 7   DIS      466 non-null    float64\n",
      " 8   RAD      466 non-null    int64  \n",
      " 9   TAX      466 non-null    int64  \n",
      " 10  PTRATIO  466 non-null    float64\n",
      " 11  B        466 non-null    float64\n",
      " 12  LSTAT    466 non-null    float64\n",
      " 13  MEDV     466 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 54.6 KB\n",
      "각 컬럼들의 결측값 현황\n",
      "CRIM       0\n",
      "ZN         0\n",
      "INDUS      0\n",
      "CHAS       0\n",
      "NOX        0\n",
      "RM         0\n",
      "AGE        0\n",
      "DIS        0\n",
      "RAD        0\n",
      "TAX        0\n",
      "PTRATIO    0\n",
      "B          0\n",
      "LSTAT      0\n",
      "MEDV       0\n",
      "dtype: int64\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 466 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     466 non-null    float64\n",
      " 1   ZN       466 non-null    float64\n",
      " 2   INDUS    466 non-null    float64\n",
      " 3   CHAS     466 non-null    float64\n",
      " 4   NOX      466 non-null    float64\n",
      " 5   RM       466 non-null    float64\n",
      " 6   AGE      466 non-null    float64\n",
      " 7   DIS      466 non-null    float64\n",
      " 8   RAD      466 non-null    int64  \n",
      " 9   TAX      466 non-null    int64  \n",
      " 10  PTRATIO  466 non-null    float64\n",
      " 11  B        466 non-null    float64\n",
      " 12  LSTAT    466 non-null    float64\n",
      " 13  MEDV     466 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 54.6 KB\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋의 결측값을 다른 값으로 대체하기\n",
    "# inplace = True 옵션으로 원본데이터 변경\n",
    "\n",
    "df['CRIM'].fillna(df['CRIM'].mean(), inplace=True) # 평균값\n",
    "df['INDUS'].fillna(df['INDUS'].mean(), inplace=True) # 평균값\n",
    "df['AGE'].fillna(df['AGE'].mean(), inplace=True) # 평균값\n",
    "df['LSTAT'].fillna(df['LSTAT'].mean(), inplace=True) # 평균값\n",
    "\n",
    "# 그 외 결측값이 있는 행은 제거하기\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print('각 컬럼들의 결측값 현황')\n",
    "print(df.isna().sum())  # 결측값이 잘 처리되었는지 확인 (결측값을 대체하거나 결측값이 있는 행을 제거해서 각 컬럼의 결측값이 0인 것을 알 수 있다.)\n",
    "print('-'*130)\n",
    "df.info() # 데이터프레임 정보 다시 확인 (총 506행의 데이터에서 466행의 결측값 없는 데이터로 바뀐 것을 확인 가능) (❗️ 결측값이 있는 행을 제거했을 뿐 인덱스는 기존과 같이 남아있다는 것 유의)\n",
    "\n",
    "\n",
    "print('각 컬럼들의 결측값 현황')\n",
    "print(df.isna().sum())  # 결측값이 잘 처리되었는지 확인 (결측값을 대체하거나 결측값이 있는 행을 제거해서 각 컬럼의 결측값이 0인 것을 알 수 있다.)\n",
    "print('-'*130)\n",
    "df.info() # 데이터프레임 정보 다시 확인 (총 506행의 데이터에서 466행의 결측값 없는 데이터로 바뀐 것을 확인 가능) (❗️ 결측값이 있는 행을 제거했을 뿐 인덱스는 기존과 같이 남아있다는 것 유의)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 📝 이상치(데이터에서 비정상적으로 크거나 작은 값) 탐지 및 제거 : 이상치는 분석결과에 큰 영향을 미쳐 모델의 성능을 저하시킬 수 있다.\n",
    "- 제거 : 이상치를 데이터셋에서 제거한다.\n",
    "- 대체 : 이상치를 특정 값으로 대체한다. \n",
    "- 변환 : 이상치를 변환하여 데이터의 분포를 조정한다. (예: 상한선이나 하한선으로 대체)\n",
    "- IQR 방법 : IQR(interquartile Range : 사분위 범위)을 사용하여 이상치를 탐지하고 처리한다. (**정수형 및 실수형 데이터**)\n",
    "    - IQR 방법은 데이터의 범위와 분포를 이해하고 이상값(outliers)을 탐지하는 데 사용되는 통계적 기법이다. IQR은 데이터셋에서 상위 25%를 제거한 중간 50%의 범위를 나타낸다. 이는 데이터의 중간값 주변의 분포를 분석할 때 유용하다.\n",
    "    - 백분위수 : 데이터를 백분위수로 나누었을 때의 값을 나타내는 통계적 척도. 백분위수는 데이터를 100개의 동일한 부분으로 나누는 방식으로, 특정 백분위수는 전테 데이터의 몇 퍼센트가 해당 값 이하인지를 나타낸다. \n",
    "    - 백분위수는 데이터의 분포를 이해하고 데이터 간의 상대적 위치를 파악하는 데 유용하게 사용된다.\n",
    "        - 0 백분위수 : 최솟값\n",
    "        - 25 백분위수 : 1사분위수(Q1), 전체 데이터의 하위 25%가 이 값 이하\n",
    "        - 50 백분위수 : 중앙값(median), 전체 데이터의 하위 50%가 이 값 이하\n",
    "        - 75 백분위수 : 3사분위수(Q3), 전체 데이터의 하위 75%가 이 값 이하\n",
    "        - 100 백분위수 : 최댓값\n",
    "        - IQR : Q3 - Q1, 즉 3사분위수에서 1사분위수를 뺀 값이다.\n",
    "    - IQR 방법을 사용한 이상값 탐지 : 이상값은 일반적으로 다음 범위를 벗어난 값으로 정의 된다.\n",
    "        - 하한값(lower_bound) : Q1 - 1.5 * IQR\n",
    "        - 상한값(upper_bound) : Q3 + 1.5 * IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  IQR 방법을 활용한 각 컬럼의 이상치 확인\n",
    "\n",
    "# 특정 열의 이상치 확인 (IQR 방법)\n",
    "# 데이터프레임의 quantile 메서드는 특정 백분위수(quantile)에 해당하는 값을 셰산하는 데 사용된다. 주어진 백분위수를 기준으로 데이터를 나눠주는 값을 반환한다.\n",
    "Q1 = df['CRIM'].quantile(0.25)\n",
    "Q3 = df['CRIM'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# 이상치 범위 설정\n",
    "lower_bound = Q1 - 1.5 * IQR # 하한값\n",
    "upper_bound = Q3 + 1.5 * IQR # 상한값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         CRIM   ZN      INDUS  CHAS    NOX     RM         AGE     DIS  RAD  \\\n",
      "356   8.98296  0.0  18.100000   1.0  0.770  6.212   97.400000  2.1222   24   \n",
      "371   9.23230  0.0  18.100000   0.0  0.631  6.216  100.000000  1.1691   24   \n",
      "373  11.10810  0.0  18.100000   0.0  0.668  4.906  100.000000  1.1742   24   \n",
      "374  18.49820  0.0  18.100000   0.0  0.668  4.138  100.000000  1.1370   24   \n",
      "377   9.82349  0.0  18.100000   0.0  0.671  6.794   98.800000  1.3580   24   \n",
      "378  23.64820  0.0  18.100000   0.0  0.671  6.380   96.200000  1.3861   24   \n",
      "379  17.86670  0.0  18.100000   0.0  0.671  6.223  100.000000  1.3861   24   \n",
      "380  88.97620  0.0  18.100000   0.0  0.671  6.968   91.900000  1.4165   24   \n",
      "381  15.87440  0.0  18.100000   0.0  0.671  6.545   99.100000  1.5192   24   \n",
      "382   9.18702  0.0  18.100000   0.0  0.700  5.536  100.000000  1.5804   24   \n",
      "384  20.08490  0.0  18.100000   0.0  0.700  4.368   91.200000  1.4395   24   \n",
      "385  16.81180  0.0  18.100000   0.0  0.700  5.277   98.100000  1.4261   24   \n",
      "386  24.39380  0.0  18.100000   0.0  0.700  4.652  100.000000  1.4672   24   \n",
      "387  22.59710  0.0  18.100000   0.0  0.700  5.000   89.500000  1.5184   24   \n",
      "392  11.57790  0.0  18.100000   0.0  0.700  5.036   97.000000  1.7700   24   \n",
      "398  38.35180  0.0  18.100000   0.0  0.693  5.453  100.000000  1.4896   24   \n",
      "399   9.91655  0.0  18.100000   0.0  0.693  5.852   77.800000  1.5004   24   \n",
      "400  25.04610  0.0  18.100000   0.0  0.693  5.987  100.000000  1.5888   24   \n",
      "402   9.59571  0.0  18.100000   0.0  0.693  6.404  100.000000  1.6390   24   \n",
      "403  24.80170  0.0  18.100000   0.0  0.693  5.349   96.000000  1.7028   24   \n",
      "404  41.52920  0.0  18.100000   0.0  0.693  5.531   85.400000  1.6074   24   \n",
      "405  67.92080  0.0  18.100000   0.0  0.693  5.683  100.000000  1.4254   24   \n",
      "406  20.71620  0.0  11.083992   0.0  0.659  4.138  100.000000  1.1781   24   \n",
      "407  11.95110  0.0  18.100000   0.0  0.659  5.608  100.000000  1.2852   24   \n",
      "410  51.13580  0.0  18.100000   0.0  0.597  5.757  100.000000  1.4130   24   \n",
      "411  14.05070  0.0  18.100000   0.0  0.597  6.657  100.000000  1.5275   24   \n",
      "412  18.81100  0.0  18.100000   0.0  0.597  4.628  100.000000  1.5539   24   \n",
      "413  28.65580  0.0  18.100000   0.0  0.597  5.155  100.000000  1.5894   24   \n",
      "414  45.74610  0.0  18.100000   0.0  0.693  4.519  100.000000  1.6582   24   \n",
      "415  18.08460  0.0  18.100000   0.0  0.679  6.434  100.000000  1.8347   24   \n",
      "416  10.83420  0.0  18.100000   0.0  0.679  6.782   90.800000  1.8195   24   \n",
      "417  25.94060  0.0  18.100000   0.0  0.679  5.304   89.100000  1.6475   24   \n",
      "418  73.53410  0.0  18.100000   0.0  0.679  5.957  100.000000  1.8026   24   \n",
      "419  11.81230  0.0  18.100000   0.0  0.718  6.824   76.500000  1.7940   24   \n",
      "420  11.08740  0.0  18.100000   0.0  0.718  6.411  100.000000  1.8589   24   \n",
      "422  12.04820  0.0  18.100000   0.0  0.614  5.648   87.600000  1.9512   24   \n",
      "425  15.86030  0.0  18.100000   0.0  0.679  5.896   95.400000  1.9096   24   \n",
      "429   9.33889  0.0  18.100000   0.0  0.679  6.380   68.518519  1.9682   24   \n",
      "431  10.06230  0.0  18.100000   0.0  0.584  6.833   94.300000  2.0882   24   \n",
      "434  13.91340  0.0  18.100000   0.0  0.713  6.208   95.000000  2.2222   24   \n",
      "435  11.16040  0.0  18.100000   0.0  0.740  6.629   94.600000  2.1247   24   \n",
      "436  14.42080  0.0  18.100000   0.0  0.740  6.461   93.300000  2.0026   24   \n",
      "437  15.17720  0.0  18.100000   0.0  0.740  6.152  100.000000  1.9142   24   \n",
      "438  13.67810  0.0  18.100000   0.0  0.740  5.935   87.900000  1.8206   24   \n",
      "439   9.39063  0.0  18.100000   0.0  0.740  5.627   93.900000  1.8172   24   \n",
      "440  22.05110  0.0  18.100000   0.0  0.740  5.818   92.400000  1.8662   24   \n",
      "441   9.72418  0.0  18.100000   0.0  0.740  6.406   97.200000  2.0651   24   \n",
      "443   9.96654  0.0  18.100000   0.0  0.740  6.485  100.000000  1.9784   24   \n",
      "444  12.80230  0.0  18.100000   0.0  0.740  5.854   96.600000  1.8956   24   \n",
      "445  10.67180  0.0  18.100000   0.0  0.740  6.459   94.800000  1.9879   24   \n",
      "447   9.92485  0.0  18.100000   0.0  0.740  6.251   96.600000  2.1980   24   \n",
      "448   9.32909  0.0  18.100000   0.0  0.713  6.185   98.700000  2.2616   24   \n",
      "454   9.51363  0.0  18.100000   0.0  0.713  6.728   94.100000  2.4961   24   \n",
      "468  15.57570  0.0  18.100000   0.0  0.580  5.926   71.000000  2.9084   24   \n",
      "469  13.07510  0.0  18.100000   0.0  0.580  5.713   56.700000  2.8237   24   \n",
      "477  15.02340  0.0  18.100000   0.0  0.614  5.304   97.300000  2.1007   24   \n",
      "478  10.23300  0.0  18.100000   0.0  0.614  6.185   96.700000  2.1705   24   \n",
      "\n",
      "     TAX  PTRATIO       B      LSTAT  MEDV  \n",
      "356  666     20.2  377.73  17.600000  17.8  \n",
      "371  666     20.2  366.15   9.530000  50.0  \n",
      "373  666     20.2  396.90  34.770000  13.8  \n",
      "374  666     20.2  396.90  37.970000  13.8  \n",
      "377  666     20.2  396.90  21.240000  13.3  \n",
      "378  666     20.2  396.90  23.690000  13.1  \n",
      "379  666     20.2  393.74  21.780000  10.2  \n",
      "380  666     20.2  396.90  17.210000  10.4  \n",
      "381  666     20.2  396.90  21.080000  10.9  \n",
      "382  666     20.2  396.90  23.600000  11.3  \n",
      "384  666     20.2  285.83  30.630000   8.8  \n",
      "385  666     20.2  396.90  30.810000   7.2  \n",
      "386  666     20.2  396.90  28.280000  10.5  \n",
      "387  666     20.2  396.90  31.990000   7.4  \n",
      "392  666     20.2  396.90  25.680000   9.7  \n",
      "398  666     20.2  396.90  30.590000   5.0  \n",
      "399  666     20.2  338.16  29.970000   6.3  \n",
      "400  666     20.2  396.90  26.770000   5.6  \n",
      "402  666     20.2  376.11  20.310000  12.1  \n",
      "403  666     20.2  396.90  19.770000   8.3  \n",
      "404  666     20.2  329.46  27.380000   8.5  \n",
      "405  666     20.2  384.97  22.980000   5.0  \n",
      "406  666     20.2  370.22  23.340000  11.9  \n",
      "407  666     20.2  332.09  12.715432  27.9  \n",
      "410  666     20.2    2.60  10.110000  15.0  \n",
      "411  666     20.2   35.05  21.220000  17.2  \n",
      "412  666     20.2   28.79  34.370000  17.9  \n",
      "413  666     20.2  210.97  20.080000  16.3  \n",
      "414  666     20.2   88.27  36.980000   7.0  \n",
      "415  666     20.2   27.25  29.050000   7.2  \n",
      "416  666     20.2   21.57  25.790000   7.5  \n",
      "417  666     20.2  127.36  26.640000  10.4  \n",
      "418  666     20.2   16.45  20.620000   8.8  \n",
      "419  666     20.2   48.45  22.740000   8.4  \n",
      "420  666     20.2  318.75  15.020000  16.7  \n",
      "422  666     20.2  291.55  14.100000  20.8  \n",
      "425  666     20.2    7.68  24.390000   8.3  \n",
      "429  666     20.2   60.72  24.080000   9.5  \n",
      "431  666     20.2   81.33  19.690000  14.1  \n",
      "434  666     20.2  100.63  15.170000  11.7  \n",
      "435  666     20.2  109.85  23.270000  13.4  \n",
      "436  666     20.2   27.49  18.050000   9.6  \n",
      "437  666     20.2    9.32  26.450000   8.7  \n",
      "438  666     20.2   68.95  34.020000   8.4  \n",
      "439  666     20.2  396.90  22.880000  12.8  \n",
      "440  666     20.2  391.45  12.715432  10.5  \n",
      "441  666     20.2  385.96  12.715432  17.1  \n",
      "443  666     20.2  386.73  18.850000  15.4  \n",
      "444  666     20.2  240.52  23.790000  10.8  \n",
      "445  666     20.2   43.06  23.980000  11.8  \n",
      "447  666     20.2  388.52  16.440000  12.6  \n",
      "448  666     20.2  396.90  18.130000  14.1  \n",
      "454  666     20.2    6.68  18.710000  14.9  \n",
      "468  666     20.2  368.74  18.130000  19.1  \n",
      "469  666     20.2  396.90  14.760000  20.1  \n",
      "477  666     20.2  349.48  24.910000  12.0  \n",
      "478  666     20.2  379.70  18.030000  14.6  \n"
     ]
    }
   ],
   "source": [
    "# 해당 컬럼에서 이상치가 있는 행 확인해보기 (하한값보다 작거나 상한값보다 큰 값은 이상치로 간주한다.)\n",
    "outliers = df[(df['CRIM'] < lower_bound) | (df['CRIM'] > upper_bound)]\n",
    "print(outliers) # CRIM 컬럼에서 이상치로 간주되는 데이터 포인트들을 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [CRIM, ZN, INDUS, CHAS, NOX, RM, AGE, DIS, RAD, TAX, PTRATIO, B, LSTAT, MEDV]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 이상치 처리 (평균값으로 대체) 맛보기용\n",
    "mean_value = df['CRIM'].mean()\n",
    "\n",
    "# 해당 열 전체의 각 데이터 포인터를 검사하여 이상치인 경우 평균값으로 대체하고, 그렇지 않은 경우 원래 값을 유지한다.\n",
    "df['CRIM'] = df['CRIM'].apply(lambda x: mean_value if x < lower_bound or x > upper_bound else x)\n",
    "\n",
    "outliers = df[(df['CRIM'] < lower_bound) | (df['CRIM'] > upper_bound)]\n",
    "print(outliers) # 이상치를 처리가 됐는지 확인해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 이 과정을 나머지 모든 컬럼에 반복해주면 데이터셋 전체의 이상치 처리가 완료된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 과정을 나머지 모든 컬럼에 반복\n",
    "\n",
    "columns = ['ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "\n",
    "for column in columns:\n",
    "    Q1 = df[column].quantile(0.25) # 1사분위\n",
    "    Q3 = df[column].quantile(0.75) # 3사분위\n",
    "    IQR = Q3 - Q1 # IQR\n",
    "    \n",
    "    # 이상치 탐지 범위 설정\n",
    "    lower_bound = Q1 - 1.5 * IQR # 하한값\n",
    "    upper_bound = Q3 + 1.5 * IQR # 상한값\n",
    "\n",
    "    # 컬럼의 평균값 계산\n",
    "    mean_value = df[column].mean()\n",
    "    \n",
    "    # 이상치를 평균값으로 대체\n",
    "    df[column] = df[column].apply(lambda x: mean_value if x < lower_bound or x > upper_bound else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 결측값과 이상치를 처리했으니 머신러닝 모델을 위한 좋은 특징을 선택하자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 📝 특징 선택(Feature Selection) 및 추출(Feature Extraction)\n",
    "\n",
    "- 머신러닝 모델 성능을 높이기 위해 중요한 특징을 선택하거나 새로운 특징을 추출하는 과정. \n",
    "- 특징 선택 과정을 통해 모델 학습에 가장 유용한 특징들을 선별하고, 이를 포함하는 새로운 입력 데이터를 만들어 모델을 학습시키는 것이다. 이런 접근법은 모델의 성능을 최적화하고 계산 비용을 줄여줄 수 있다.\n",
    "- 한 마디로, 특징을 선택한다는 것은 **기존 입력 데이터에서, 특정 컬럼을 선택하여 모델 학습에 가장 유용한 특징(컬럼)만을 포함하는 새로운 입력 데이터를 만든다**는 것이다. 불필요한 특징을 제거하여 계산 비용을 줄임!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 scikit-learn 라이브러리의 SelectKBest 클래스를 사용하여 상위 5개의 중요한 특징을 선택하는 과정이다.\n",
    "\n",
    "#### **SelectKBest 클래스**\n",
    "\n",
    "- scikit-learn 라이브러리의 SelectKBest 클래스는 가장 좋은 K개의 특징을 선택하는 데 사용된다.\n",
    "- 여기서 '가장 좋은'을 결정하는 기준은 특징 선택 방법에 따라 달라지는데, 여러 가지 방법이 있지만 SelectKBest와 f_classif를 사용하는 경우 '가장 좋은' 특징을 결정하는 기준은 ANOVA F-검정(Analysis of Variance F-test)을 기반으로 한다.\n",
    "\n",
    "#### **ANOVA F-검정**\n",
    "\n",
    "- 목적: **각 특징이 타겟 변수와 얼마나 강한 상관관계를 가지는지** 평가한다.\n",
    "- F-통계량: **각 특징의 설명력이 타겟 변수에 얼마나 기여하는지**를 나타내는 통계량이다.\n",
    "    - 높은 F-통계량: 해당 특징이 타겟 변수와 강한 상관관계를 가지며, '좋은' 특징으로 간주된다.\n",
    "\n",
    "- 특징 선택 과정\n",
    "    - 특징 평가: 각 특징에 대해 ANOVA F-검정을 수행하여 F-통계량을 계산한다.\n",
    "    - 순위 매기기: F-통계량에 따라 특징을 내림차순으로 정렬한다.\n",
    "    - 특징 선택: 가장 높은 F-통계량을 가진 상위 K개의 특징을 선택한다. \n",
    "  \n",
    "#### **f_classif**\n",
    "\n",
    "- 바로 위에서 설명한 분산분석(ANOVA) F-검정을 수행하는 함수로, **각 특징의 중요도를 평가**한다.\n",
    "- 분류 문제에서 자주 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선택된 특징의 인덱스: [ 2  4  5  9 12]\n",
      "선택된 특징: Index(['INDUS', 'NOX', 'RM', 'TAX', 'LSTAT'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 모델의 학습에 중요한 특징을 선택하는 과정\n",
    "\n",
    "# 특징 선택방법 설정\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "\n",
    "# 입력 데이터 X와 타겟 변수 y설정 \n",
    "# 예시로 'MEDV'(데이터셋에서 주택 가격의 중간값을 나타내는 컬럼)를 타겟 변수로 설정. 즉, 'MEDV'는 예측하고자 하는 타겟 변수이기 때문에 입력데이터에서 제외해야 한다.(정답지 주고 학습시키면 안됨!)\n",
    "\n",
    "# X : 입력 데이터. 모델이 학습하는데 사용하는 특징(features)들을 (현재는 모두)담고 있는 데이터프레임. 학습을 통해 예측해야 하는 타겟변수인 'MEDV'를 제외시킨 모든 열이 포함된 데이터프레임이다.\n",
    "X = df.drop(columns=['MEDV']) \n",
    "\n",
    "# y : 예측해야 하는 목표값을 담고 있는 시리즈\n",
    "y = df['MEDV'] # 데이터셋에서 MEDV 열을 선택하여 타겟변수 y로 설정한다.\n",
    "\n",
    "# SelectKBest 객체 생성(score_func는 SelectKBest 클래스에서 각 특징(특성)의 중요도를 평가할 함수로, 여기서는 f_classif를 지정해줬다. k 옵션을 통해 상위 k개의 특징을 선택한다.)\n",
    "# 여기서 selector는 상위 k개의 특징을 선택할 수 있도록 하는 메커니즘을 설정하는 객체이다.\n",
    "selector = SelectKBest(score_func=f_classif, k=5) \n",
    "\n",
    "# 데이터에 맞추기 (fit) 및 변환 (transform)\n",
    "\n",
    "# 상위 k개의 특징을 선택할 수 있도록 하는 메커니즘인 selector 객체에 fit_transform 메서드를 사용하여 입력 데이터 X와 타겟변수 y에 맞춰서 학습(fit)하고(학습한 다음에 상관성 높은 상위 k개의 특징을 뽑는 것), 상위 5개의 중요한 특징을 선택하여 변환(transform)한다.\n",
    "\n",
    "# 결과적으로 선택된 상위 5개의 특징(컬럼)만 포함된 새로운 데이터 X_new 가 생성된다.\n",
    "# fit_transform 메서드는 Scikit-learn과 같은 머신러닝 라이브러리에서 데이터 전처리와 특징 선택과 같은 작업을 수행한다.\n",
    "# 먼저 데이터에 맞추어 모델이나 변환기를 학습(fit)한다. 이 과정에서는 모델이 데이터의 구조나 분포를 학습하게 된다.\n",
    "# 학습된 모델이나 변환기를 사용하여 데이터를 변환(transform)한다. 이 과정에서는 학습된 정보를 바탕으로 데이터를 실제로 변환하여 새로운 형식(여기서는 k개의 특징(열)이 담긴 넘파이 배열)으로 반환한다.\n",
    "X_new = selector.fit_transform(X, y) \n",
    "\n",
    "# get_support 메서드는 sklearn의 특징 선택 클래스에서 사용되며, '선택된 특징의 인덱스를 반환'한다.\n",
    "# 이를 통해 어떤 특징(어떤 행)이 선택되었는지 확인할 수 있다.\n",
    "# indices=True 옵션은 메서드가, 선택된 특징의 인덱스를 반환하도록 지정한다. 선택된 특징의 인덱스는 해당 특징이 입력 데이터에서 몇 번째 '열'에 위치해 있는지를 나타낸다.\n",
    "selected_features = selector.get_support(indices=True) \n",
    "print(\"선택된 특징의 인덱스:\", selected_features) \n",
    "print(\"선택된 특징:\", X.columns[selected_features]) # 기존의 X 데이터에서 선택된 상위 5개의 특징 컬럼을 보여줌 (특징 컬럼이 몇 번째 열에 위치해있는지를 반환하는 인덱스라고 했잖음)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⭐️ X_new는 SelectKBest를 사용하여 기존의 입력 데이터 X에서, 중요한 상위 K개의 특징만을 포함하는 새로운 입력 데이터를 만든 것이다! ⭐️\n",
    "\n",
    "X_new에는 선택된 상위 K개의 특징(컬럼)만 포함되어 있고, 나머지 특징들은 모두 제거된 상태다.\n",
    "\n",
    "요약\n",
    "- 기존의 입력 데이터 X : 원래의 모든 특징(컬럼)을 포함한 데이터프레임.\n",
    "- 새로운 입력 데이터 X_new : SelectKBest에 의해 선택된 중요한 상위 K개의 특징(컬럼)만을 포함한 넘파이 배열(array). X_new는 X와는 달리 선택된 k개의 열만을 갖게 된다.\n",
    "\n",
    "X_new는 fit_transform 메서드의 결과로 생성된 NumPy 배열(array)이다. 이는 모델 학습과 같은 머신러닝 작업에 최적화된 형식이다.\n",
    "\n",
    "- NumPy 배열은 성능이 뛰어나고, 다차원 배열 연산을 쉽게 수행할 수 있기 때문에 머신러닝 모델 학습에 매우 적합하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.31 ,   0.538,   6.575, 296.   ,   4.98 ],\n",
       "       [  7.07 ,   0.469,   6.421, 242.   ,   9.14 ],\n",
       "       [  7.07 ,   0.469,   7.185, 242.   ,   4.03 ],\n",
       "       ...,\n",
       "       [ 11.93 ,   0.573,   6.976, 273.   ,   5.64 ],\n",
       "       [ 11.93 ,   0.573,   6.794, 273.   ,   6.48 ],\n",
       "       [ 11.93 ,   0.573,   6.03 , 273.   ,   7.88 ]])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 입력 데이터 X_new 확인\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(466, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_new.shape) # 여전히 466행이고, 상위 5개 특징 열만 뽑아서 5열인 배열임을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_new (데이터프레임으로 바꿔준 것)\n",
      "     INDUS    NOX     RM    TAX      LSTAT\n",
      "0     2.31  0.538  6.575  296.0   4.980000\n",
      "1     7.07  0.469  6.421  242.0   9.140000\n",
      "2     7.07  0.469  7.185  242.0   4.030000\n",
      "3     2.18  0.458  6.998  222.0   2.940000\n",
      "4     2.18  0.458  7.147  222.0  12.715432\n",
      "..     ...    ...    ...    ...        ...\n",
      "461  11.93  0.573  6.593  273.0  12.715432\n",
      "462  11.93  0.573  6.120  273.0   9.080000\n",
      "463  11.93  0.573  6.976  273.0   5.640000\n",
      "464  11.93  0.573  6.794  273.0   6.480000\n",
      "465  11.93  0.573  6.030  273.0   7.880000\n",
      "\n",
      "[466 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# 배열을 데이터프레임으로 바꿔서 확인해보자\n",
    "X_new_df = pd.DataFrame(X_new, columns=X.columns[selected_features]) \n",
    "print(\"X_new (데이터프레임으로 바꿔준 것)\")\n",
    "print(X_new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 특징 선택이 완료된 새로운 입력데이터 X_new까지 구해놨으니, 모델을 만들어보자 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할 (머신러닝 모델을 학습시키기 전에 데이터를 훈련데이터와 테스트 데이터로 나누는 중요한 과정)\n",
    "# train_test_split 함수를 사용하여 데이터를 훈련 데이터와 테스트 데이터로 나눈다.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 분할 (80% 훈련 데이터, 20% 테스트 데이터)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터 스케일링 (모델 학습을 돕기 위해 모든 특징을 일정한 범위로 변환하는 것)\n",
    "# StandardScaler는 각 특징을 평균이 0이고, 분산이 1이 되도록 표준화하여 모델이 특정 특징에 대해 과도하게 민감하게 반응하는 것을 방지한다.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 훈련데이터 스케일링 : fit_transform 메서드는 훈련 데이터 X_train 데이터를 평균이 0, 분산이 1이 되도록 변환해준다.\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# 테스트 데이터 스케일링 : transform 메서드는 훈련 데이터에서 계산된 평균과 표준편차를 사용하여 테스트 데이터 X_test를 표준화한다.\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_test_split(X_new, y, test_size=0.2, random_state=42)\n",
    "- X_new: 선택된 상위 5개의 특징(컬럼)을 포함하는 입력 데이터\n",
    "- y: 타겟 변수 (예: 주택 가격)\n",
    "- test_size = 0.2: 전체 데이터의 20%를 테스트 데이터로 사용하겠다.\n",
    "- random_state=42: 결과를 재현 가능하게 하는 임의의 시드 값이다. (다시 돌렸을 때도 같은 결과가 나오게 하기 위함)\n",
    "\n",
    "반환값\n",
    "- X_train: 훈련 데이터의 입력 변수 (80%) \n",
    "- X_test: 테스트 데이터의 입력 변수 (20%)\n",
    "- y_train: 훈련 데이터의 타겟 변수 (80%)\n",
    "- y_test: 테스트 데이터의 타겟 변수 (20%)\n",
    "- 훈련용 X 데이터랑 훈련용 y 데이터로 모델을 학습시키고, 이후에 테스트용 X를 입력 데이터로 줘서 테스트용 y(정답)이 나오는지 확인하는 것이다. 이걸 잘 하면 모델의 성능이 좋은 것! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🤖 선형회귀 모델\n",
    "- 선형회귀는 종속 변수와 하나 이상의 독립변수 간의 선형관계를 모델링하는 방법이다.\n",
    "- 단순선형회귀 : 하나의 독립변수와 하나의 종속변수 간의 관계를 모델링\n",
    "- 다중선형회귀 : 여러 독립변수와 하나의 종속 변수 간의 관계를 모델링\n",
    "- 용례 : 연속형 변수 예측(주택가격, 온도 등), 시간 시계열 예측(다음 달의 판매량), 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 선형회귀 모델 학습\n",
    "# LinearRegression 클래스는 선형회귀 모델을 만든다.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 선형회귀 모델 초기화 및 학습\n",
    "# model 객체는 선형회귀 모델을 나타낸다.\n",
    "model = LinearRegression()\n",
    "\n",
    "# fit 메서드를 사용하여 모델을 학습시킨다.\n",
    "# 모델이 X_train과 y_train을 사용하여 패턴을 학습한다.\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fit 메서드는 머신러닝 모델을 학습시키는 데 사용되는 중요한 함수이다. \n",
    "fit 메서드는 주어진 데이터에 모델을 맞추는 과정, 즉 학습하는 과정을 수행한다. \n",
    "\n",
    "- 모델 학습: 주어진 입력 데이터(X)와 타겟 변수(y)를 사용하여 모델의 내부 파라미터를 학습한다. 모델은 이 데이터를 통해 패턴을 인식하고, 이후 예측을 위한 준비를 마친다.\n",
    "- 데이터 적합화: 데이터의 특성과 구조를 학습하여 모델이 최적의 예측을 할 수 있도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_error: 2.455045106800746\n",
      "Mean Squared Error: 9.709087415273196\n",
      "R^2 Score: 0.7264160944964467\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터를 사용하여 모델 평가\n",
    "# 평가 지표를 사용하기 위해 sklearn.metrics 모듈에서 mean_squared_error와 r2_score 함수를 임포트한다.\n",
    "# mean_squared_error 함수: 평균 제곱 오차(MSE)를 계산하여 반환.\n",
    "# r2_score : 결정 계수(R^2 점수)를 계산하여 반환.\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# 예측값 생성\n",
    "# 모델에 훈련데이터를 fit(학습)시켰으니 이제 predict 메서드를 사용하여 테스트 데이터를 받아 예측값을 생성하자. (훈련용으로 안쓰고 남은 X 데이터 남아있었지.)\n",
    "y_pred = model.predict(X_test)\n",
    "# y_pred: 예측된 타겟 변수\n",
    "\n",
    "# 평가 지표 계산\n",
    "mae = mean_absolute_error(y_test, y_pred) # 예측값과 실제값 간의 평균 절대 오차를 나타낸다.(0에 가까울수록 좋음)\n",
    "mse = mean_squared_error(y_test, y_pred) # 예측값과 실제값 간의 차이의 제곱 평균(0에 가까울수록 좋은 것)\n",
    "r2 = r2_score(y_test, y_pred) # 모델의 설명력을 나타내는 지표. (값이 1에 가까울수록 좋음)\n",
    "\n",
    "print(f\"mean_absolute_error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🤖 의사결정나무 모델\n",
    "- 지도학습의 분류모델 중 의사결정나무(Decision Tree)란, 예측 모델 중 하나로, 데이터의 특징(feature)을 기준으로 의사결정 규칙을 만들고 이를 바탕으로 데이터를 분류하거나 회귀(입력데이터에 대한 타겟변수를 예측하는 것)하는데 사용한다. \n",
    "- 의사결정나무는 트리구조를 가지며, 각 내부 노드는 데이터의 특정 특징에 대한 테스트를 나타내고, 각 가지(branch)는 테스트 결과를 나타내며, 각 리츠 노드(leaf)는 클래스 레이블을 나타낸다.\n",
    "    - 노드 : 트리의 각 분기점으로, 하나의 특징에 대한 테스트를 나타낸다. \n",
    "    - 루트 노드: 트리의 최상위 노드로, 전체 데이터셋을 나타낸다.\n",
    "    - 리프 노드: 트리의 끝 노드로, 최종 클래스 레이블을 나타낸다.\n",
    "    - 깊이: 트리의 루트 노드부터 리프 노드까지의 최대 거리이다.\n",
    "    - 분할 기준: 노드를 나눌 때 사용하는 기준.\n",
    "        - 정보 이득(Information Gain) : 엔트로피 값으로 데이터를 나누는 기준이다. 엔트로피는 불확실성을 나타내며, 엔트로피가 낮을수록 불확실성이 적다.\n",
    "        - 지니 계수(Gini Index) : 불순도를 측정하는 방법으로, 지니계수가 낮을수록 불순도가 적다.\n",
    "\n",
    "➡️ 강의에서 분류모델 의사결정나무 알려줘서 그걸로 했더니, 분류모델(DecisionTreeClassifier)을 연속값(회귀목표)으로 학습시키려고 했다는 오류가 발생했다. 분류모델은 이산형 클래스(범주형 데이터)를 예측하는 데 사용되며, 연속형 데이터(실제 숫자 값)를 예측할 수 없다고 한다.\n",
    "➡️ 따라서 회귀모델의 의사결정나무 모델을 사용하겠다. (DecisionTreeRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_error: 2.943311113140352\n",
      "Mean Squared Error: 18.800077963366277\n",
      "R^2 Score: 0.47024900147690063\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# 의사결정나무 모델 생성 및 학습\n",
    "tr_model = DecisionTreeRegressor(random_state=42)\n",
    "tr_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측값 생성\n",
    "y_pred_tr = tr_model.predict(X_test)\n",
    "\n",
    "# 평가지표계산\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae_tr = mean_absolute_error(y_test, y_pred_tr) # 예측값과 실제값 간의 평균 절대 오차를 나타낸다.(0에 가까울수록 좋음)\n",
    "mse_tr = mean_squared_error(y_test, y_pred_tr) # 예측값과 실제값 간의 차이의 제곱 평균(0에 가까울수록 좋은 것)\n",
    "r2_tr = r2_score(y_test, y_pred_tr) # 모델의 설명력을 나타내는 지표. (값이 1에 가까울수록 좋음)\n",
    "\n",
    "print(f\"mean_absolute_error: {mae_tr}\")\n",
    "print(f\"Mean Squared Error: {mse_tr}\")\n",
    "print(f\"R^2 Score: {r2_tr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 앙상블 학습\n",
    "\n",
    "- 앙상블 학습(Ensemble Learning)은 여러 개의 학습 모델을 결합하여 하나의 강력한 모델을 만드는 기법이다.\n",
    "- 앙상블 학습은 개별 모델의 예측을 결합함으로써, 단일 모델보다 더 높은 예측 성능과 일반화 능력을 얻을 수 있다.\n",
    "- 앙상블 학습의 주요 기법으로는 배깅(Bagging)과 부스팅(Boosting)이 있다.\n",
    "- 배깅(Bootstrap Aggregating) : 다수결 원리\n",
    "    - 배깅은 여러 개의 학습 모델을 병렬로 학습시키고, 그 예측 결과를 평균 또는 다수결로 결합하는 앙상블 기법이다. 여러 모델의 예측을 결합함으로써 과적합을 줄일 수 있다.\n",
    "    - 데이터의 샘플링 과정에서 부트 스트래핑 기법을 사용하여, 원본 데이터셋에서 중복을 허용한 무작위 샘플을 생성한다. \n",
    "    - 각 모델은 서로 다른 데이터 샘플을 학습하게 되어, 모델 간의 상관성을 줄이고 예측 성능을 향상시킨다.  \n",
    "- 부스팅(Boosting) : 약한 학습기를 결합한 강한 학습기\n",
    "    - 부스팅은 여러 개의 약한 학습기를 순차적으로 학습시키고, 그 예측 결과를 결합하여 강한 학습기를 만드는 앙상블 기법이다. 약한 학습기를 결합하여 높은 예측 성능을 얻을 수 있다.\n",
    "    - 부스팅은 이전 모델이 잘못 예측한 데이터 포인트에 가중치를 부여하여, 다음 모델이 이를 더 잘 학습하도록 한다. 이전 모델의 오류를 보완하는 방식으로 학습이 진행된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🤖 배깅 모델\n",
    "\n",
    "- estimator 옵션 : 배깅에 사용할 기본 학습기의 유형을 지정한다. 예를 들어, estimator=DecisionTreeRegressor() 는 각 기본 학습기로 의사결정나무 회귀모델을 사용한다는 의미이다. 이것은 배깅과정에서 각 기본학습기가 어떤 알고리즘을 사용할지를 결정한다.\n",
    "- n_estimators 옵션 : 앙상블 기법에서, 여러 번의 반복 학습을 통해 생성되는 기본 학습기의 개수를 지정한다\n",
    "- 이는 모델의 다양성을 높이고 예측 성능을 향상시키는데 중요한 역할을 한다. 지정한 숫자만큼의 기본학습기를 생성하고, 각각의 학습기는 서로 다른 데이터 샘플에 대해 학습되며, 서로 다른 예측을 제공한다. 이렇게 모든 기본학습기의 예측을 결합하여 최종 예측을 만든다. 회귀 문제의 경우 평균값을 사용하고, 분류 문제의 경우 다수결 투표를 사용한다. 여러 모델의 예측을 결합함으로써 각 모델의 오류가 상쇄되어 최종 예측의 정확도를 높이는 데 도움을 준다.\n",
    "\n",
    "n_estimators: \"100명의 화가가 있다\"고 생각할 수 있다. 여기서 100은 n_estimators로, 여러 개의 개별 학습기(화가)를 의미한다.\n",
    "\n",
    "estimator: \"이 화가들은 모두 같은 종류의 브러쉬를 사용해 그림을 그린다\"고 생각할 수 있다. 여기서 estimator는 학습기가 어떤 유형의 모델(브러쉬)을 사용할지를 결정합니다.\n",
    "\n",
    "위를 종합하면, \n",
    "배깅 모델에서 n_estimators=100은 무작위로 100개의 다른 머신러닝 모델을 가져오는 것이 아니라, estimator 옵션에서 지정한 동일한 모델을 100개 생성하는 것이다.\n",
    "\n",
    "bagging_model = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=100, random_state=42) \n",
    "위 코드는 100개의 DecisionTreeRegressor 모델을 사용하여 각자 원본데이터에서 무작위로 샘플링된 다른 데이터를 학습하여 예측하고 최종적으로 이들을 결합하여 최종 예측을 생성하는 배깅 모델을 생성하는 코드인 것이다!\n",
    "이 방법을 통해 단일 모델보다 더 안정적이고 강력한 예측 성능을 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배깅 모델의 MSE: 8.909975885558874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 배깅 모델 생성 (estimator : 머신러닝 모델)\n",
    "# estimator: 개별 기본 학습기로 사용할 모델을 지정. 여기서는 DecisionTreeRegressor를 사용함\n",
    "# n_estimators: 생성할 기본 학습기의 개수. 여기서는 100개의 의사결정 나무를 생성하겠다는 뜻\n",
    "# random_state: 랜덤 시드 값으로, 결과의 재현성을 보장하기 위함\n",
    "bagging_model = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=100, random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred_bagging = bagging_model.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "mse_bagging = mean_squared_error(y_test, y_pred_bagging)\n",
    "print(f'배깅 모델의 MSE: {mse_bagging}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🤖 랜덤포레스트\n",
    "- 랜덤 포레스트는 배깅 기법을 기반으로 하지만, 추가적인 무작위성을 도입하여 모델의 다양성을 증가시키고 예측 성능을 향상시킨 앙상블 학습 모델이다.\n",
    "- 배깅에서는 여러 모델을 기본 학습기로 사용할 수 있었지만, 랜덤 포레스트는 항상 의사결정나무를 기본 학습기로 사용한다. \n",
    "- 배깅은 데이터 샘플링만 무작위였다면, 랜덤포레스트는 데이터 샘플링과 특징선택 둘 다 무작위이다. \n",
    "- 배깅은 모든 특징을 사용하여 학습한다면, 랜덤포레스트는 각 분할에서 무작위로 선택된 하위 집합의 특징만 사용하여 학습한다. \n",
    "- 이렇게 여러 개의 의사결정나무를 학습시키고, 그 예측 결과를 결합하여 최종예측을 수행한다.\n",
    "- 각 트리가 독립적으로 학습되기 때문에, 과적합을 방지하고 예측 성능을 향상시킬 수 있다.\n",
    "  \n",
    "##### 랜덤포레스트의 구조\n",
    "- 랜던 포레스트는 여러 개의 결정 트리로 구성된다.\n",
    "- 각 결정 트리는 데이터의 무작위 샘풀을 사용하여 학습되며, 트리의 예측 결과를 평균 또는 다수결로 결합하여 최종 예측을 수행한다.\n",
    "- 랜덤포레스트는 두 가지 무작위성을 도입하여 모델의 다양성을 증가시키고 과적합을 방지한다.\n",
    "    - 데이터 샘플링의 무작위성 : 각 결정 트리는 원본 데이터셋에서 무작위로 샘플링된 데이터로 학습된다.\n",
    "    - 특성 선택의 무작위성 : 각 노드에서 분할을 수행할 때, 무작위로 선택된 특성의 일부만을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_error: 2.1076901652817095\n",
      "Mean Squared Error: 8.771439929071077\n",
      "R^2 Score: 0.7528372451451915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 랜덤 포레스트 모델 생성\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# 평가지표계산\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf) # 예측값과 실제값 간의 평균 절대 오차를 나타낸다.(0에 가까울수록 좋음)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf) # 예측값과 실제값 간의 차이의 제곱 평균(0에 가까울수록 좋은 것)\n",
    "r2_rf = r2_score(y_test, y_pred_rf) # 모델의 설명력을 나타내는 지표. (값이 1에 가까울수록 좋음)\n",
    "\n",
    "print(f\"mean_absolute_error: {mae_rf}\")\n",
    "print(f\"Mean Squared Error: {mse_rf}\")\n",
    "print(f\"R^2 Score: {r2_rf}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
